#libraries
import numpy as np
import matplotlib.pyplot as plt
from keras.layers import Input
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from keras.layers import Dropout, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D
import cv2
from sklearn.model_selection import train_test_split
import os
import pandas as pd
import random
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
print('done')

################# Parameters #####################

path = "C:/Users/ramachandran/Desktop/project/Train"  # Folder containing subfolders for each class (0 to 42)
labelFile = 'C:/Users/ramachandran/Desktop/project/labels.csv'  # File with class names and mappings
batch_size_val = 50  # how many to process together
steps_per_epoch_val = 2000
epochs_val = 30
imageDimesions = (32, 32, 3)
testRatio = 0.2    # 20% of the images for testing
validationRatio = 0.2  # 20% of the remaining 80% for validation

print('done')

############################### Importing of the Images
count = 0
images = []
classNo = []
myList = os.listdir(path)
print("Total Classes Detected:", len(myList))
noOfClasses = len(myList)
print("Importing Classes.....")
for x in range(0, len(myList)):
    myPicList = os.listdir(path + "/" + str(count))
    for y in myPicList:
        curImg = cv2.imread(os.path.join(path, str(count), y))  # Updated to ensure correct path usage
        curImg = cv2.resize(curImg, (32, 32))  # Ensure all images are resized to 32x32
        images.append(curImg)
        classNo.append(count)
    print(count, end=" ")
    count += 1
print(" ")
images = np.array(images)
classNo = np.array(classNo)

print('done')

############################### Split Data
X_train, X_test, y_train, y_test = train_test_split(images, classNo, test_size=testRatio)
X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validationRatio)

# X_train = ARRAY OF IMAGES TO TRAIN
# y_train = CORRESPONDING CLASS ID

steps_per_epoch_val = len(X_train) // batch_size_val
validation_steps = len(X_test) // batch_size_val

print('done')

############################### TO CHECK IF NUMBER OF IMAGES MATCHES TO NUMBER OF LABELS FOR EACH DATASET
print("Data Shapes")
print("Train", end=""); print(X_train.shape, y_train.shape)
print("Validation", end=""); print(X_validation.shape, y_validation.shape)
print("Test", end=""); print(X_test.shape, y_test.shape)

print('done')

# Assertions to check the integrity of data
assert(X_train.shape[0] == y_train.shape[0]), "The number of images does not match the number of labels in training set"
assert(X_validation.shape[0] == y_validation.shape[0]), "The number of images does not match the number of labels in validation set"
assert(X_test.shape[0] == y_test.shape[0]), "The number of images does not match the number of labels in test set"
assert(X_train.shape[1:] == imageDimesions), "The dimensions of the Training images are wrong"
assert(X_validation.shape[1:] == imageDimesions), "The dimensions of the Validation images are wrong"
assert(X_test.shape[1:] == imageDimesions), "The dimensions of the Test images are wrong"

print('done')

############################### READ CSV FILE
data = pd.read_csv(labelFile)
print("Data shape ", data.shape, type(data))

############################### DISPLAY SOME SAMPLE IMAGES OF ALL THE CLASSES
num_of_samples = []
cols = 5
num_classes = noOfClasses
fig, axs = plt.subplots(nrows=num_classes, ncols=cols, figsize=(5, num_classes * 2))  # Adjust figsize based on num_classes
fig.subplots_adjust(hspace=0.5, wspace=0.2)  # Adjust spacing between images

for i in range(cols):
    for j, row in data.iterrows():
        x_selected = X_train[y_train == j]
        axs[j][i].imshow(x_selected[random.randint(0, len(x_selected) - 1), :, :], cmap=plt.get_cmap("gray"))
        axs[j][i].axis("off")
        if i == 2:
            axs[j][i].set_title(str(j) + "-" + row["Name"])
            num_of_samples.append(len(x_selected))

plt.show()  # This will show the plot with adjusted spacing

print('done')

############################### DISPLAY A BAR CHART SHOWING NO OF SAMPLES FOR EACH CATEGORY
print(num_of_samples)
plt.figure(figsize=(12, 4))
plt.bar(range(0, num_classes), num_of_samples)
plt.title("Distribution of the training dataset")
plt.xlabel("Class number")
plt.ylabel("Number of images")
plt.show()

############################### PREPROCESSING THE IMAGES
def grayscale(img):
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    return img

def equalize(img):
    img = cv2.equalizeHist(img)
    return img

def preprocessing(img):
    img = grayscale(img)     # Convert to grayscale
    img = equalize(img)      # Standardize lighting
    img = img / 255          # Normalize to [0, 1]
    return img

print('done')

# Preprocess all images
X_train = np.array(list(map(preprocessing, X_train)))
X_validation = np.array(list(map(preprocessing, X_validation)))
X_test = np.array(list(map(preprocessing, X_test)))

cv2.imshow("GrayScale Image Sample", X_train[random.randint(0, len(X_train) - 1)])

print('done')

############################### ADD A DEPTH OF 1
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)
X_validation = X_validation.reshape(X_validation.shape[0], X_validation.shape[1], X_validation.shape[2], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)

print('done')

############################### IMAGE AUGMENTATION
dataGen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.2,
                             shear_range=0.1, rotation_range=10)
dataGen.fit(X_train)
batches = dataGen.flow(X_train, y_train, batch_size=20)
X_batch, y_batch = next(batches)

# Display augmented image samples
fig, axs = plt.subplots(1, 15, figsize=(20, 5))
fig.tight_layout()

for i in range(15):
    axs[i].imshow(X_batch[i].reshape(imageDimesions[0], imageDimesions[1]))
    axs[i].axis('off')
plt.show()

y_train = to_categorical(y_train, noOfClasses)
y_validation = to_categorical(y_validation, noOfClasses)
y_test = to_categorical(y_test, noOfClasses)

print('done')

############################### Define the Model

def myModel():
    model = Sequential()
    
    # Use Input layer explicitly
    model.add(Input(shape=(32, 32, 1)))  # Instead of passing input_shape to Conv2D
    
    model.add(Conv2D(60, (5, 5), activation='relu'))
    model.add(Conv2D(60, (5, 5), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    
    model.add(Conv2D(30, (5, 5), activation='relu'))
    model.add(Conv2D(30, (5, 5), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    
    model.add(Dropout(0.5))  # Add Dropout for regularization
    model.add(Flatten())
    
    model.add(Dense(500, activation='relu'))
    model.add(Dropout(0.5))
    
    model.add(Dense(noOfClasses, activation='softmax'))
    
    # Compile the model
    model.compile(optimizer=Adam(learning_rate=0.001),  # Use learning_rate, not lr
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    
    return model

print('done')

############################### TRAINING THE MODEL
model = myModel()

# Print model summary
print(model.summary())

# Training with fit() (fit_generator is deprecated)
history = model.fit(dataGen.flow(X_train, y_train, batch_size=batch_size_val),
                    steps_per_epoch=steps_per_epoch_val, epochs=epochs_val,
                    validation_data=(X_validation, y_validation),
                    shuffle=True)

print('Training done')

############################### PLOTTING TRAINING HISTORY
plt.figure(1)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['training', 'validation'])
plt.title('Loss')
plt.xlabel('epoch')

plt.figure(2)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.legend(['training', 'validation'])
plt.title('Accuracy')
plt.xlabel('epoch')
plt.show()

############################### EVALUATE THE MODEL
score = model.evaluate(X_test, y_test, verbose=0)
print('Test Score:', score[0])
print('Test Accuracy:', score[1])

############################### SAVE THE MODEL
model_path = 'trained_model.h5'
model.save(model_path)

# Final Training Accuracy and Loss
training_loss = history.history['loss'][-1]
training_accuracy = history.history['accuracy'][-1]
validation_loss = history.history['val_loss'][-1]
validation_accuracy = history.history['val_accuracy'][-1]

print(f"Final Training Loss: {training_loss:.4f}")
print(f"Final Training Accuracy: {training_accuracy:.4f}")
print(f"Final Validation Loss: {validation_loss:.4f}")
print(f"Final Validation Accuracy: {validation_accuracy:.4f}")

# Testing on random images from Test folder
# Load and preprocess random images from the "Test" folder
import matplotlib.pyplot as plt

# ClassId to Traffic Sign Name Mapping
class_names = {
    0: 'Speed limit (20km/h)', 1: 'Speed limit (30km/h)', 2: 'Speed limit (50km/h)',
    3: 'Speed limit (60km/h)', 4: 'Speed limit (70km/h)', 5: 'Speed limit (80km/h)',
    6: 'End of speed limit (80km/h)', 7: 'Speed limit (100km/h)', 8: 'Speed limit (120km/h)',
    9: 'No passing', 10: 'No passing for vehicles over 3.5 metric tons', 11: 'Right-of-way at the next intersection',
    12: 'Priority road', 13: 'Yield', 14: 'Stop', 15: 'No vehicles', 16: 'Vehicles over 3.5 metric tons prohibited',
    17: 'No entry', 18: 'General caution', 19: 'Dangerous curve to the left', 20: 'Dangerous curve to the right',
    21: 'Double curve', 22: 'Bumpy road', 23: 'Slippery road', 24: 'Road narrows on the right', 25: 'Road work',
    26: 'Traffic signals', 27: 'Pedestrians', 28: 'Children crossing', 29: 'Bicycles crossing',
    30: 'Beware of ice/snow', 31: 'Wild animals crossing', 32: 'End of all speed and passing limits',
    33: 'Turn right ahead', 34: 'Turn left ahead', 35: 'Ahead only', 36: 'Go straight or right', 37: 'Go straight or left',
    38: 'Keep right', 39: 'Keep left', 40: 'Roundabout mandatory', 41: 'End of no passing',
    42: 'End of no passing by vehicles over 3.5 metric tons'
}

# Load and preprocess random images from the "Test" folder
test_image_folder = "C:/Users/ramachandran/Desktop/project/Test"  # Update the folder path accordingly
random_images = random.sample(os.listdir(test_image_folder), 5)  # Pick 5 random images

# Set up the figure for displaying images and their predictions
fig, axs = plt.subplots(1, len(random_images), figsize=(20, 5))

for i, img_name in enumerate(random_images):
    img_path = os.path.join(test_image_folder, img_name)
    img = cv2.imread(img_path)
    img_resized = cv2.resize(img, (32, 32))  # Resize to match the input dimensions
    img_preprocessed = preprocessing(img_resized)  # Preprocess using your preprocessing function
    img_preprocessed = img_preprocessed.reshape(1, 32, 32, 1)  # Add batch dimension

    # Predict the class and probabilities
    predictions = model.predict(img_preprocessed)
    predicted_class = np.argmax(predictions)
    probability = np.max(predictions) * 100

    # Get the traffic sign name from the class_names dictionary
    traffic_sign_name = class_names[predicted_class]

    # Display the image
    axs[i].imshow(cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for displaying
    axs[i].axis('off')
    axs[i].set_title(f"{traffic_sign_name}\n{probability:.2f}%")

plt.show()


#Performance Metrices

# Predict on the test set
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

# Classification report
print("Classification Report:\n", classification_report(y_true, y_pred_classes))

# Confusion matrix
conf_matrix = confusion_matrix(y_true, y_pred_classes)

# Plot confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted Class')
plt.ylabel('True Class')
plt.show()

# Overall accuracy
accuracy = np.sum(y_pred_classes == y_true) / len(y_true)
print(f"Overall Test Accuracy: {accuracy * 100:.2f}%")
